var documenterSearchIndex = {"docs":
[{"location":"#Getting-Started","page":"Home","title":"Getting Started","text":"We will look at a split plot experiment, described in chapter 10 of:\n\nGoos, Peter, and Bradley Jones. Optimal design of experiments: a case study approach. John Wiley & Sons, 2011.\n\nSplit-plot experiments have hard-to-change factors and easy-to-change factors. Hard-to-change factors are not properly randomized, they are kept at the same factor setting for multiple observations. The dataset can thus be split up into blocks, where the hard-to-change factors remain constant. These blocks are also called whole plots. The observations within such a block are more similar to one another than observations coming from a different block. A random intercept per block is introduced to deal with the correlation between observations. In the below dataset, FRH and RRH are hard-to-change, while YA and GC are easy-to-change. The WP column shows that there are 10 blocks in the dataset in which FRH and RRH remain constant. Efficiency is the output we want to model.\n\n<details><summary>Click here to expand the details loading the data.</summary>\n\n#! format: off\nusing DataFrames\ndf = DataFrame(\n  WP = [1,1,1,1,1,\n        2,2,2,2,2,\n        3,3,3,3,3,\n        4,4,4,4,4,\n        5,5,5,5,5,\n        6,6,6,6,6,\n        7,7,7,7,7,\n        8,8,8,8,8,\n        9,9,9,9,9,\n        10,10,10,10,10],\n  FRH = [-1,-1,-1,-1,-1,\n         0,0,0,0,0,\n         1,1,1,1,1,\n         -1,-1,-1,-1,-1,\n         0,0,0,0,0,\n         0,0,0,0,0,\n         1,1,1,1,1,\n         -1,-1,-1,-1,-1,\n         0,0,0,0,0,\n         1,1,1,1,1],\n  RRH = [-1,-1,-1,-1,-1,\n         -1,-1,-1,-1,-1,\n         -1,-1,-1,-1,-1,\n         0,0,0,0,0,\n         0,0,0,0,0,\n         0,0,0,0,0,\n         0,0,0,0,0,\n         1,1,1,1,1,\n         1,1,1,1,1,\n         1,1,1,1,1],\n  YA = [-1,1,0,1,-1,\n        1,0,1,0,-1,\n        1,1,-1,-1,0,\n        -1,0,1,0,-1,\n        0,1,0,-1,0,\n        1,0,0,0,-1,\n        0,1,0,0,-1,\n        -1,1,0,1,-1,\n        -1,0,0,0,1,\n        -1,1,-1,1,0],\n  GC = [-1,1,0,-1,1,\n        1,0,-1,1,0,\n        -1,1,-1,1,0,\n        0,1,0,-1,1,\n        -1,0,0,1,0,\n        0,0,0,0,-1,\n        -1, 1,0,1,0,\n        -1,-1,0,1,1,\n        0,-1,0,1,1,\n        1,-1,-1,0,1],\n  EFFICIENCY = [\n                0.873,0.969,0.959,0.821,1.019,\n                0.921,0.923,0.821,0.958,0.914,\n                0.705,0.861,0.756,0.861,0.78,\n                0.999,1.06,0.91,0.854,1.082,\n                0.841,0.885,0.905,1.025,0.936,\n                0.844,0.891,0.902,0.871,0.833,\n                0.786,0.879,0.86,0.905,0.87,\n                0.98,0.907,1.045,1.094,1.159,\n                1.0,0.901,0.99,1.059,1.025,\n                0.991,0.828,0.853,0.923,0.997\n                ]\n  )\n\n</details>\n\ndf[1:10, :]\n\ndf[45:50, :]\n\nWe work with a full quadratic model, where the intercept is allowed to vary between blocks. First, we get the output using only MixedModels. Here, the p-values for the main effects (first-order terms) are all below 1e-10.\n\nusing MixedModels\nfm = @formula(\n    EFFICIENCY ~\n        1 +\n    (1 | WP) +\n    FRH +\n    RRH +\n    YA +\n    GC +\n    FRH & RRH +\n    FRH & YA +\n    FRH & GC +\n    RRH & YA +\n    RRH & GC +\n    YA & GC +\n    FRH & FRH +\n    RRH & RRH +\n    YA & YA +\n    GC & GC\n)\nm = fit(MixedModel, fm, df; REML=true)\n\nNow we look at the adjustments made in the Kenward Roger approach. The p-values for the main effects of the hard-to-change factors are much larger. This is primarily because the degrees of freedom for these factors are very limited.\n\nSimilar results hold for the second-order terms. Terms involving only the hard-to-change factors have limited degrees of freedom. The interactions involving both a hard and an easy-to-change factor have similar degrees of freedom as terms only involving easy-to-change factors.\n\nusing MixedModelsSmallSample\nkr = small_sample_adjust(m, KenwardRoger(; fim=ExpectedFIM()))\n\nThe standard errors on the estimates are also slightly different. However, for this specific experiment, the adjustment does not have a large effect. An example where there is a large difference in standard error will be added later.","category":"section"},{"location":"#Multiple-random-effects","page":"Home","title":"Multiple random effects","text":"using CSV\nusing DataFrames\nusing MixedModels\n\nusing MixedModelsSmallSample\n\ndf = DataFrame(MixedModels.dataset(:sleepstudy))\nfm = @formula(reaction ~ 1 + days + (1 + days | subj))\nm = fit(MixedModel, fm, df; REML=true)\n\nkr = small_sample_adjust(m, KenwardRoger(; fim=ExpectedFIM())) # or ObservedFIM()","category":"section"},{"location":"#More-examples","page":"Home","title":"More examples","text":"","category":"section"},{"location":"#Scalar-Random-Effects","page":"Home","title":"Scalar Random Effects","text":"Bioequivalence (Homogeneous)\nBlocked experiment\nSplit-plot experiment\nStrip-plot experiment","category":"section"},{"location":"#Vector-Random-Effects","page":"Home","title":"Vector Random Effects","text":"Bioequivalence (Intermediate)\nSingle random slope","category":"section"},{"location":"#Similar-software","page":"Home","title":"Similar software","text":"The R package pbkrtest\nJMP\nSAS","category":"section"},{"location":"#How-It-Works","page":"Home","title":"How It Works","text":"The computations follow the same high-level flow for both Kenward-Roger and Satterthwaite:\n\nCompute V(theta), V(theta)^-1, and derivative matrices for either Unstructured or FactorAnalytic.\nCompute W = I(θ)^{-1} via vcov_varpar, using either ObservedFIM or ExpectedFIM.\nFor KenwardRoger, compute the bias-corrected covariance of β (see MixedModelsSmallSample.compute_adjusted_covariance).\nCompute denominator degrees of freedom and (for KR) the F-scaling factor (see MixedModelsSmallSample.compute_dof).","category":"section"},{"location":"#API-Reference","page":"Home","title":"API Reference","text":"","category":"section"},{"location":"#Main-Functions","page":"Home","title":"Main Functions","text":"","category":"section"},{"location":"#Adjustment-Methods","page":"Home","title":"Adjustment Methods","text":"","category":"section"},{"location":"#Options","page":"Home","title":"Options","text":"","category":"section"},{"location":"#Result-Types","page":"Home","title":"Result Types","text":"","category":"section"},{"location":"#Internals","page":"Home","title":"Internals","text":"These types and functions are not exported but may be useful for understanding or extending the package.","category":"section"},{"location":"#Variance-Decomposition","page":"Home","title":"Variance Decomposition","text":"","category":"section"},{"location":"#Covariance-Adjustment-Computation","page":"Home","title":"Covariance Adjustment Computation","text":"","category":"section"},{"location":"#Degrees-of-Freedom-Computation","page":"Home","title":"Degrees of Freedom Computation","text":"","category":"section"},{"location":"#MixedModelsSmallSample.MixedModelsSmallSample","page":"Home","title":"MixedModelsSmallSample.MixedModelsSmallSample","text":"MixedModelsSmallSample\n\nSmall-sample corrections for linear mixed models fitted by MixedModels.jl.\n\nLinear Mixed Model\n\nA linear mixed model expresses the n-vector of responses as\n\ny = Xbeta + Zu + varepsilon quad\nu sim mathcalN(0 G(theta)) quad\nvarepsilon sim mathcalN(0 sigma^2 I_n)\n\nwhere X is the n times p fixed-effects design matrix, beta is the p-vector of fixed-effects coefficients, Z is the random-effects design matrix, u is the vector of random effects with covariance G(theta), and varepsilon is the residual error.\n\nThe marginal variance of y is\n\nV(theta) = ZG(theta)Z^top + sigma^2 I_n\n\nThe Small-Sample Problem\n\nThe generalized least squares estimator hatbeta has covariance\n\nPhi(theta) = (X^top V(theta)^-1 X)^-1\n\nStandard inference replaces theta with its REML estimate hattheta, yielding hatPhi = Phi(hattheta), and uses asymptotic approximations (e.g., treating t-statistics as normally distributed). For small samples, this ignores:\n\nBias in hatPhi due to estimating theta\nUncertainty in hattheta affecting the reference distribution\n\nThis package implements two corrections:\n\nKenward-Roger (KenwardRoger): Applies a bias correction to hatPhi and uses a scaled F-distribution with approximate degrees of freedom.\nSatterthwaite (Satterthwaite): Uses moment-matching to approximate degrees of freedom for the t/F reference distribution.\n\nReferences\n\nKenward, M. G. and Roger, J. H. (1997). \"Small sample inference for fixed effects from restricted maximum likelihood.\" Biometrics, 53(3), 983-997.\nSatterthwaite, F. E. (1946). \"An Approximate Distribution of Estimates of Variance Components.\" Biometrics Bulletin, 2(6), 110-114.\nFai, A. H.-T. and Cornelius, P. L. (1996). \"Approximate F-tests of multiple degree of freedom hypotheses in generalized least squares analyses of unbalanced split-plot experiments.\" Journal of Statistical Computation and Simulation, 54(4), 363-378.\n\nSee Also\n\nsmall_sample_adjust: Apply KR or SW adjustment to a fitted model\nsmall_sample_ftest: Perform an adjusted F-test for contrasts\n\n\n\n\n\n","category":"module"},{"location":"#MixedModelsSmallSample.small_sample_adjust","page":"Home","title":"MixedModelsSmallSample.small_sample_adjust","text":"small_sample_adjust(m::MixedModel, method) -> LinearMixedModelAdjusted\n\nApply small-sample corrections to a fitted linear mixed model.\n\nThis is the main entry point for computing adjusted inference. The function:\n\nValidates that m is unweighted; KenwardRoger additionally requires a REML fit\nComputes W = I(theta)^-1, the asymptotic covariance of hattheta (see vcov_varpar)\nFor KenwardRoger: computes adjusted covariance Phi_A\n\n(see compute_adjusted_covariance)\n\nComputes denominator degrees of freedom nu_k for each fixed effect (see compute_dof)\n\nArguments\n\nm::MixedModel: A fitted LinearMixedModel from MixedModels.jl (must use REML for KR; ML or REML for SW)\nmethod: Either KenwardRoger or Satterthwaite\n\nReturns\n\nLinearMixedModelAdjusted\n\nThe returned object can be displayed to show adjusted coefficient tables with corrected standard errors (KR only) and degrees of freedom.\n\nExample\n\nusing MixedModels, MixedModelsSmallSample\nm = fit(MixedModel, @formula(y ~ x + (1|g)), data; REML=true)\nkr = small_sample_adjust(m, KenwardRoger())\nsw = small_sample_adjust(m, Satterthwaite())\n\nSee Also\n\nsmall_sample_ftest: Perform F-tests on contrasts\n\n\n\n\n\n","category":"function"},{"location":"#MixedModelsSmallSample.small_sample_ftest","page":"Home","title":"MixedModelsSmallSample.small_sample_ftest","text":"small_sample_ftest(m::LinearMixedModelAdjusted, L) -> (ν, F*)\n\nCompute an adjusted F-test for the null hypothesis L^topbeta = 0.\n\nReturns (ν F^*) where (ν λ) is obtained from compute_dof and F^* = λF with F = β^top Mβq and M = L(L^topPhi L)^-1L^top (using the unadjusted covariance Phi).\n\nArguments\n\nm: An adjusted model (LinearMixedModelAdjusted)\nL: Contrast matrix (p times q) where p = number of fixed effects\n\nReturns\n\nν: Denominator degrees of freedom\nF*: Scaled F-statistic\n\nUnder H_0, F^* sim F(q nu) approximately.\n\nExample\n\nkr = small_sample_adjust(model, KenwardRoger())\nL = [0 1 0; 0 0 1]'  # Test β₂ = β₃ = 0\nν, Fstar = small_sample_ftest(kr, L)\npvalue = 1 - cdf(FDist(size(L,2), ν), Fstar)\n\n\n\n\n\nsmall_sample_ftest(m::MixedModel, L; method=KenwardRoger()) -> (ν, F*)\n\nConvenience wrapper that first applies small_sample_adjust then computes the F-test.\n\nEquivalent to:\n\nm_adj = small_sample_adjust(m, method)\nsmall_sample_ftest(m_adj, L)\n\nArguments\n\nm: A fitted MixedModel (must use REML for KR; ML or REML for SW)\nL: Contrast matrix\nmethod: KenwardRoger or Satterthwaite\n\n\n\n\n\n","category":"function"},{"location":"#MixedModelsSmallSample.vcov_varpar","page":"Home","title":"MixedModelsSmallSample.vcov_varpar","text":"vcov_varpar(m::MixedModel; fim=ObservedFIM(), parameterization=Unstructured())\n\nCompute W = I(θ)^{-1}, the asymptotic covariance of the fitted variance parameters.\n\nThe Fisher information I(θ) is computed using either ObservedFIM or ExpectedFIM.\n\n\n\n\n\n","category":"function"},{"location":"#MixedModelsSmallSample.KenwardRoger","page":"Home","title":"MixedModelsSmallSample.KenwardRoger","text":"KenwardRoger(; fim=ObservedFIM(), parameterization=Unstructured())\n\nKenward-Roger method for small_sample_adjust and small_sample_ftest.\n\nSee also Satterthwaite for an alternative method.\n\n\n\n\n\n","category":"type"},{"location":"#MixedModelsSmallSample.Satterthwaite","page":"Home","title":"MixedModelsSmallSample.Satterthwaite","text":"Satterthwaite(; fim=ObservedFIM(), parameterization=Unstructured())\n\nSatterthwaite method for small_sample_adjust and small_sample_ftest.\n\nSee also KenwardRoger for an alternative method.\n\n\n\n\n\n","category":"type"},{"location":"#MixedModelsSmallSample.ObservedFIM","page":"Home","title":"MixedModelsSmallSample.ObservedFIM","text":"ObservedFIM\n\nUse the observed (Hessian-based) Fisher Information Matrix for the variance parameters.\n\nLet V, V^-1, dV_i and d^2V_ij come from VarianceDecomposition. Define\n\nPhi = (X^top V^-1 X)^-1qquad\nP = V^-1 - V^-1XPhiX^top V^-1qquad\nr = y - Xhatbeta\n\nThen the observed information is\n\nI^textobs_ij(theta) =\n-frac12operatornametrleft(P dV_i P dV_jright)\n+ r^top V^-1 dV_i P dV_j V^-1 r\n+ frac12operatornametrleft(P d^2V_ijright)\n- frac12 r^top V^-1 d^2V_ij V^-1 r\n\nSee Also\n\nExpectedFIM: Alternative using expected values\nvcov_varpar: Computes the inverse of the FIM\n\n\n\n\n\n","category":"type"},{"location":"#MixedModelsSmallSample.ExpectedFIM","page":"Home","title":"MixedModelsSmallSample.ExpectedFIM","text":"ExpectedFIM\n\nUse the expected Fisher Information Matrix for the variance parameters.\n\nLet V^-1, dV_i, P_i and Q_ij come from VarianceDecomposition, and define Phi = (X^top V^-1 X)^-1.\n\nThen the expected information used by vcov_varpar is\n\nI^textexp_ij(theta) = frac12operatornametrleft(V^-1 dV_i V^-1 dV_jright)\n- operatornametr(PhiQ_ij)\n+ frac12operatornametr(PhiP_iPhiP_j)\n\nSee Also\n\nObservedFIM: Alternative using observed Hessian\nvcov_varpar: Computes the inverse of the FIM\n\n\n\n\n\n","category":"type"},{"location":"#MixedModelsSmallSample.Unstructured","page":"Home","title":"MixedModelsSmallSample.Unstructured","text":"Unstructured\n\nUnstructured (variance component) parameterization.\n\nIn this parameterization, the marginal variance is linear in the variance parameters. Writing the model as V(theta) = sigma^2 I_n + sum_b Z_b G_b(theta) Z_b^top, Unstructured parameterizes each block covariance G_b(theta) by its unique (co)variance components.\n\nGradient Structure\n\nBecause V is linear in theta, the derivatives are trivial: each partial Vpartialtheta_i is constant and partial^2 V(partialtheta_ipartialtheta_j) = 0.\n\nThis implies the R_ij terms used by the Kenward-Roger covariance correction vanish.\n\nSee Also\n\nFactorAnalytic: Alternative Cholesky-based parameterization\n\n\n\n\n\n","category":"type"},{"location":"#MixedModelsSmallSample.FactorAnalytic","page":"Home","title":"MixedModelsSmallSample.FactorAnalytic","text":"FactorAnalytic\n\nFactor analytic (Cholesky) parameterization.\n\nFor each random-effects block b, decompose the block covariance as G_b = L_b L_b^top with L_b lower triangular. The variance parameters are sigma^2 and the free elements of the L_b.\n\nThe marginal variance is\n\nV = sigma^2 I_n + sum_b Z_b G_b Z_b^top = sigma^2 I_n + sum_b Z_b L_b L_b^top Z_b^top\n\nFor MixedModels.jl models, the internal random-effects factor is stored as a relative factor lambda_b; we use the scaled factor L_b = sigmalambda_b.\n\nDerivatives of V\n\nThe derivative of V with respect to a Cholesky element L_bij uses the chain rule through G_b = L_b L_b^top:\n\nfracpartial Vpartial L_ij = Z_b fracpartial G_bpartial L_ij Z_b^top\nqquad\nfracpartial G_bpartial L_ij = E_ij L_b^top + L_b E_ij^top\n\nwhere E_ij is the elementary matrix with a 1 at position (ij).\n\nThe second derivatives are non-zero. For indices within the same block,\n\nfracpartial^2 G_bpartial L_i_1 j_1partial L_i_2 j_2\n= delta_j_1 j_2(E_i_1 i_2 + E_i_2 i_1)\n\nand hence\n\nfracpartial^2 Vpartial L_i_1 j_1partial L_i_2 j_2\n= Z_bfracpartial^2 G_bpartial L_i_1 j_1partial L_i_2 j_2Z_b^top\n\nUnlike Unstructured, this parameterization has non-zero second derivatives partial^2 V  partial L_ij partial L_kl, which must be included in the Kenward-Roger bias correction.\n\nSee Also\n\nUnstructured: Alternative with zero second derivatives\n\n\n\n\n\n","category":"type"},{"location":"#MixedModelsSmallSample.LinearMixedModelAdjusted","page":"Home","title":"MixedModelsSmallSample.LinearMixedModelAdjusted","text":"LinearMixedModelAdjusted{T<:LinearMixedModel, O<:AbstractLinearMixedModelAdjustment}\n\nA wrapper around a LinearMixedModel that holds the small-sample adjusted results.\n\nFields\n\nm: The original LinearMixedModel.\nadj: The adjustment option used (KenwardRoger or Satterthwaite).\nvarcovar_adjusted: The adjusted variance-covariance matrix of the fixed effects (corrected for KR, unadjusted for SW).\nW: The asymptotic covariance matrix of the variance parameters.\nP: Derived matrix (P_i).\nQ: Derived matrix (Q_{ij}) (optional, nothing for Satterthwaite).\nR: Derived matrix (R_{ij}) (optional, nothing for Satterthwaite).\nR_factor: Scaling factor for (R_{ij}) (0.0 for Satterthwaite).\nν: The denominator degrees of freedom for each fixed effect coefficient.\n\n\n\n\n\n","category":"type"},{"location":"#MixedModelsSmallSample.VarianceDecomposition","page":"Home","title":"MixedModelsSmallSample.VarianceDecomposition","text":"VarianceDecomposition\n\nCached matrices derived from the marginal covariance V(θ) and its derivatives.\n\nLet θs denote the variance parameters, and write dVs[i] = ∂V/∂θ_i and d2Vs[i,j] = ∂²V/(∂θ_i∂θ_j).\n\nThis struct stores V, Vinv, θs, dVs, d2Vs, and the derived matrices\n\nP_i = -X^top V^-1 dV_i V^-1 X\nqquad\nQ_ij = X^top V^-1 dV_i V^-1 dV_j V^-1 X\nqquad\nR_ij = X^top V^-1 d^2V_ij V^-1 X\n\nand R_factor. R_factor is a parameterization-dependent scalar applied to R_{ij} in the Kenward-Roger covariance bias correction (see compute_adjusted_covariance).\n\nThe definition of θ (and thus the rest of the calculated quantities here) depends on the chosen parameterization; see Unstructured and FactorAnalytic.\n\n\n\n\n\n","category":"type"},{"location":"#MixedModelsSmallSample.compute_adjusted_covariance","page":"Home","title":"MixedModelsSmallSample.compute_adjusted_covariance","text":"compute_adjusted_covariance(Φ, vd, W, method) -> Matrix\n\nCompute the (possibly adjusted) covariance matrix of fixed effects.\n\nFor KenwardRoger, applies the bias correction:\n\nPhi_A = hatPhi + 2hatPhiBhatPhi\n\nwhere the bias matrix B accounts for the variability in estimating theta:\n\nB = sum_ij W_ij bigl(Q_ij - P_ihatPhiP_j + R_textfactorcdot R_ijbigr)\n\nHere W is the asymptotic covariance of hattheta, and P_i Q_ij R_ij are defined in VarianceDecomposition. The R_factor is -1/4 for FactorAnalytic parameterization and 1 for Unstructured.\n\nFor Satterthwaite, returns Phi unchanged (no bias correction).\n\nArguments\n\nΦ: Unadjusted covariance matrix (X^top V^-1 X)^-1\nvd: VarianceDecomposition containing derivative matrices\nW: Asymptotic covariance of variance parameters\nmethod: Adjustment method (KenwardRoger or Satterthwaite)\n\n\n\n\n\n","category":"function"},{"location":"#MixedModelsSmallSample.compute_dof","page":"Home","title":"MixedModelsSmallSample.compute_dof","text":"compute_dof(m::LinearMixedModelAdjusted, L) -> (ν, λ)\n\nCompute degrees of freedom and F-statistic scaling factor for contrast L.\n\nDispatches to the specific method based on m.adj:\n\nFor KenwardRoger: computes scaled F-statistic with λ  1\nFor Satterthwaite: returns λ = 1 (no scaling)\n\nArguments\n\nm: A LinearMixedModelAdjusted from small_sample_adjust\nL: Contrast matrix (p  q) where p = number of fixed effects\n\nReturns\n\nν: Denominator degrees of freedom\nλ: F-statistic scaling factor (1.0 for Satterthwaite)\n\n\n\n\n\ncompute_dof(::KenwardRoger, m, L)\n\nKenward-Roger denominator degrees of freedom and F-scaling factor.\n\nFor testing H_0 L^topbeta = 0 with q constraints, the standard Wald F-statistic F = beta^top M beta  q (where M = L(L^topPhi L)^-1L^top) is scaled to F^* = lambda F. The pair (nu lambda) is chosen so that F^* approximately follows an F(q nu) distribution.\n\nAlgorithm\n\nCompute moment quantities:\nA_1 = sum_ij W_ij operatornametr(MPhi P_i Phi) operatornametr(MPhi P_j Phi)\nA_2 = sum_ij W_ij operatornametr(MPhi P_i Phi MPhi P_j Phi)\nCompute intermediate terms:\nB = fracA_1 + 6A_22q quad\ng = frac(q+1)A_1 - (q+4)A_2(q+2)A_2\nc_1 = fracg3q + 2(1-g) quad\nc_2 = fracq-g3q + 2(1-g) quad\nc_3 = fracq+2-g3q + 2(1-g)\nCompute expectation and variance of the scaled statistic:\nE^* = frac11 - A_2q quad\nV^* = frac2q cdot frac1 + c_1 B(1-c_2 B)^2 (1-c_3 B)\nMatch to F-distribution moments:\nrho = fracV^*2(E^*)^2 quad\nnu = 4 + fracq+2qrho - 1 quad\nlambda = fracnuE^*(nu - 2)\n\n\n\n\n\ncompute_dof(::Satterthwaite, m, L)\n\nSatterthwaite denominator degrees of freedom for contrast L.\n\nFor a scalar contrast c^topbeta, the variance is v = c^topPhic. The Satterthwaite approximation matches the first two moments of hatv to a scaled chi-squared distribution, yielding:\n\nnu = frac2v^2(nabla_theta v)^top W (nabla_theta v)\n\nwhere the gradient is nabla_theta v = -c^topPhiP_iPhic_i and W is the asymptotic covariance of hattheta.\n\nMultivariate Contrasts\n\nFor a matrix L (multiple constraints), the algorithm:\n\nComputes the eigendecomposition of L^topPhiL\nTransforms to orthogonal contrasts tildeL = L cdot texteigenvectors\nComputes nu_i for each orthogonal contrast\nCombines using: nu = 2 E_Q  (E_Q - q) where E_Q = sum_i nu_i(nu_i - 2)\n\nReference\n\nSatterthwaite, F. E. (1946). \"An Approximate Distribution of Estimates of Variance Components.\" Biometrics Bulletin, 2(6), 110-114.\n\n\n\n\n\n","category":"function"}]
}
