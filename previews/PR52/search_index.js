var documenterSearchIndex = {"docs":
[{"location":"#MixedModelsSmallSample","page":"Home","title":"MixedModelsSmallSample","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The confidence intervals and hypothesis tests for the fixed effects in MixedModels.jl are based on large sample approximations. This package implements small sample corrections for these intervals and tests, as described in:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Kenward, Michael G., and James H. Roger. \"Small sample inference for fixed effects from restricted maximum likelihood.\" Biometrics (1997): 983-997,","category":"page"},{"location":"","page":"Home","title":"Home","text":"and in:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Hrong-Tai Fai, Alex, and Paul L. Cornelius. \"Approximate F-tests of multiple degree of freedom hypotheses in generalized least squares analyses of unbalanced split-plot experiments.\" Journal of statistical computation and simulation 54.4 (1996): 363-378.","category":"page"},{"location":"#Getting-Started","page":"Home","title":"Getting Started","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"We will look at a split plot experiment, described in chapter 10 of:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Goos, Peter, and Bradley Jones. Optimal design of experiments: a case study approach. John Wiley & Sons, 2011.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Split-plot experiments have hard-to-change factors and easy-to-change factors. Hard-to-change factors are not properly randomized, they are kept at the same factor setting for multiple observations. The dataset can thus be split up into blocks, where the hard-to-change factors remain constant. These blocks are also called whole plots. The observations within such a block are more similar to one another than observations coming from a different block. A random intercept per block is introduced to deal with the correlation between observations. In the below dataset, FRH and RRH are hard-to-change, while YA and GC are easy-to-change. The WP column shows that there are 10 blocks in the dataset in which FRH and RRH remain constant. Efficiency is the output we want to model.","category":"page"},{"location":"","page":"Home","title":"Home","text":"<details><summary>Click here to expand the details loading the data.</summary>","category":"page"},{"location":"","page":"Home","title":"Home","text":"#! format: off\nusing DataFrames\ndf = DataFrame(\n  WP = [1,1,1,1,1,\n        2,2,2,2,2,\n        3,3,3,3,3,\n        4,4,4,4,4,\n        5,5,5,5,5,\n        6,6,6,6,6,\n        7,7,7,7,7,\n        8,8,8,8,8,\n        9,9,9,9,9,\n        10,10,10,10,10],\n  FRH = [-1,-1,-1,-1,-1,\n         0,0,0,0,0,\n         1,1,1,1,1,\n         -1,-1,-1,-1,-1,\n         0,0,0,0,0,\n         0,0,0,0,0,\n         1,1,1,1,1,\n         -1,-1,-1,-1,-1,\n         0,0,0,0,0,\n         1,1,1,1,1],\n  RRH = [-1,-1,-1,-1,-1,\n         -1,-1,-1,-1,-1,\n         -1,-1,-1,-1,-1,\n         0,0,0,0,0,\n         0,0,0,0,0,\n         0,0,0,0,0,\n         0,0,0,0,0,\n         1,1,1,1,1,\n         1,1,1,1,1,\n         1,1,1,1,1],\n  YA = [-1,1,0,1,-1,\n        1,0,1,0,-1,\n        1,1,-1,-1,0,\n        -1,0,1,0,-1,\n        0,1,0,-1,0,\n        1,0,0,0,-1,\n        0,1,0,0,-1,\n        -1,1,0,1,-1,\n        -1,0,0,0,1,\n        -1,1,-1,1,0],\n  GC = [-1,1,0,-1,1,\n        1,0,-1,1,0,\n        -1,1,-1,1,0,\n        0,1,0,-1,1,\n        -1,0,0,1,0,\n        0,0,0,0,-1,\n        -1, 1,0,1,0,\n        -1,-1,0,1,1,\n        0,-1,0,1,1,\n        1,-1,-1,0,1],\n  EFFICIENCY = [\n                0.873,0.969,0.959,0.821,1.019,\n                0.921,0.923,0.821,0.958,0.914,\n                0.705,0.861,0.756,0.861,0.78,\n                0.999,1.06,0.91,0.854,1.082,\n                0.841,0.885,0.905,1.025,0.936,\n                0.844,0.891,0.902,0.871,0.833,\n                0.786,0.879,0.86,0.905,0.87,\n                0.98,0.907,1.045,1.094,1.159,\n                1.0,0.901,0.99,1.059,1.025,\n                0.991,0.828,0.853,0.923,0.997\n                ]\n  )","category":"page"},{"location":"","page":"Home","title":"Home","text":"</details>","category":"page"},{"location":"","page":"Home","title":"Home","text":"df[1:10, :]","category":"page"},{"location":"","page":"Home","title":"Home","text":"df[45:50, :]","category":"page"},{"location":"","page":"Home","title":"Home","text":"We work with a full quadratic model, where the intercept is allowed to vary between blocks. First, we get the output using only MixedModels. Here, the p-values for the main effects (first-order terms) are all below 1e-10.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using MixedModels\nfm = @formula(\n    EFFICIENCY ~\n        1 +\n    (1 | WP) +\n    FRH +\n    RRH +\n    YA +\n    GC +\n    FRH & RRH +\n    FRH & YA +\n    FRH & GC +\n    RRH & YA +\n    RRH & GC +\n    YA & GC +\n    FRH & FRH +\n    RRH & RRH +\n    YA & YA +\n    GC & GC\n)\nm = fit(MixedModel, fm, df; REML=true)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Now we look at the adjustments made in the Kenward Roger approach. The p-values for the main effects of the hard-to-change factors are much larger. This is primarily because the degrees of freedom for these factors are very limited.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Similar results hold for the second-order terms. Terms involving only the hard-to-change factors have limited degrees of freedom. The interactions involving both a hard and an easy-to-change factor have similar degrees of freedom as terms only involving easy-to-change factors.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using MixedModelsSmallSample\nkr = adjust_KR(m; FIM_σ²=:expected)","category":"page"},{"location":"","page":"Home","title":"Home","text":"The standard errors on the estimates are also slightly different. However, for this specific experiment, the adjustment does not have a large effect. An example where there is a large difference in standard error will be added later.","category":"page"},{"location":"#Multiple-random-effects","page":"Home","title":"Multiple random effects","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"using CSV\nusing DataFrames\nusing MixedModels\n\nusing MixedModelsSmallSample\n\ndf = DataFrame(MixedModels.dataset(:sleepstudy))\nfm = @formula(reaction ~ 1 + days + zerocorr(1 + days | subj)) # zerocorr is necessary\nm = fit(MixedModel, fm, df; REML=true)","category":"page"},{"location":"","page":"Home","title":"Home","text":"kr = adjust_KR(m; FIM_σ²=:expected) # :expected or :observed","category":"page"},{"location":"#Mathematical-details","page":"Home","title":"Mathematical details","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To quantify the uncertainty on the estimates of the variance components, either the observed or the expected Fisher information matrix can be used, by passing :expected or :observed to the keyword argument FIM_σ². Observed is the default option.","category":"page"},{"location":"#Limitations","page":"Home","title":"Limitations","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Currently, correlated random effects are not supported. In the above example the zerocorr is necessary.","category":"page"},{"location":"#More-examples","page":"Home","title":"More examples","text":"","category":"section"},{"location":"#Random-intercept","page":"Home","title":"Random intercept","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Blocked experiment\nSplit-plot experiment\nStrip-plot experiment","category":"page"},{"location":"#Random-intercept-and-main-effects","page":"Home","title":"Random intercept and main effects","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Single random slope","category":"page"},{"location":"#Similar-software","page":"Home","title":"Similar software","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The R package pbkrtest\nJMP\nSAS","category":"page"},{"location":"#API","page":"Home","title":"API","text":"","category":"section"}]
}
